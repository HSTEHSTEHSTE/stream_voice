data:
  base_path: /home/hltcoe/xli/ARTS/stream_voice/data
  codec_path: /home/hltcoe/xli/ARTS/stream_voice/data/LibriTTS_audiodec
  asr_path: /home/hltcoe/xli/ARTS/stream_voice/data/LibriTTS_icefall
  wav_path: /home/hltcoe/xli/ARTS/stream_voice/corpora/LibriTTS
  train_sets: ['train-clean-100', 'train-clean-360', 'train-other-500']
  # train_sets: ['train-clean-100', 'train-clean-360']
  # train_sets: ['train-clean-100']
  dev_sets: ['dev-clean', 'dev-other']
  test_sets: ['test-clean', 'test-other']
  sampling_rate: 24000

exp_path: /home/hltcoe/xli/ARTS/stream_voice/exp/exp
exp_name: b10_h2_l3_lr1_w1_d9

device: cuda
max_seq_len: 1001 # must be [multiples of (frame_ratio + 1)] + 1
batch_size: 8

model:
  codebook_dim: 1024
  codebook_num: 8
  codebook_ids: [0, 1, 2, 3, 4, 5, 6, 7]
  codebook_weights: [16.0, 8.0, 4.0, 4.0, 2.0, 2.0, 1.0, 1.0]
  n_layers: 8
  n_heads: 4
  emb_dim: 384
  transformer_dim: 1024
  norm_eps: 1.0e-5
  rope_theta: 500000
  multiple_of: 256
  frame_ratio: 1
  prompt_len: 100
  codebook_layers:
    n_layers: 2
    n_heads: 4
    transformer_dim: 1024
    norm_eps: 1.0e-5
    multiple_of: 256
    rope_theta: 500000

training:
  epoch: 100000
  report_every: 10
  valid_every: 2500
  save_every: 5000
  mask_ratio: 0.02
  num_span: 10
  grad_clip_thresh: 1.0
  valid_length_limit: 50
  train_length_limit: 1000000000
  restore_step: infer
  keep_checkpoints: 10
  n_warmup_step: 10000
  gradient_acc_steps: 2
  input_dropout: 0.9
  top_k: 10
  temperature: 1
  optim:
    betas: [0.9, 0.98]
    eps: 1.0e-9
    weight_decay: 0.
    init_lr: 1.0e-1